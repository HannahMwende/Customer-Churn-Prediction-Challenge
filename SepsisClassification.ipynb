{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "## Introduction:\n",
    "In the pursuit of enhancing healthcare outcomes and patient care, this project aims to develop a predictive model for the early detection of sepsis. \n",
    "\n",
    "Sepsis is a life-threatening condition that arises when the body's response to infection causes organ dysfunction. \n",
    "Timely identification and intervention are crucial for improving patient outcomes.\n",
    "\n",
    "This project aligns with the CRISP-DM framework, emphasizing a structured and iterative approach to developing a robust sepsis prediction model.\n",
    "\n",
    "### CRISP-DM Framework:\n",
    "1. Business Understanding:\n",
    "Understand the clinical context, the impact of sepsis on patient outcomes, and the requirements of healthcare professionals. Define the goals and success criteria for the project.\n",
    "\n",
    "2. Data Understanding:\n",
    "Explore the dataset to gain insights into the variables, their distributions, and potential relationships. Identify any missing or outlier values that may impact model performance.\n",
    "\n",
    "3. Data Preparation:\n",
    "Preprocess the data, handle missing values, encode categorical variables, and scale features as needed. Prepare the dataset for model training and evaluation.\n",
    "\n",
    "4. Modeling:\n",
    "Select appropriate machine learning algorithms and train multiple models. Tune hyperparameters to optimize performance and ensure the robustness of the chosen model.\n",
    "\n",
    "5. Evaluation:\n",
    "Assess the model's performance using metrics such as accuracy, precision, recall, and F1 score. Validate the model on a separate dataset to gauge its generalization capabilities.\n",
    "\n",
    "6. Deployment:\n",
    "Implement the model into a system that healthcare professionals can use for sepsis risk assessment. Provide necessary documentation for seamless integration into clinical workflows.\n",
    "\n",
    "7. Monitoring and Maintenance:\n",
    "Establish mechanisms for ongoing model monitoring, ensuring continued accuracy and relevance. Address any drift in data distribution and update the model as needed.\n",
    "\n",
    "\n",
    "\n",
    "## Background:\n",
    "Sepsis is a critical concern in healthcare, with its early diagnosis posing a significant challenge. \n",
    "\n",
    "Machine learning offers a promising avenue for developing models that can assist medical professionals in identifying patients at risk of developing sepsis. \n",
    "\n",
    "By leveraging a dataset comprising various patient attributes, we aim to construct a predictive model that can accurately classify the presence or absence of sepsis.\n",
    "\n",
    "## Objectives:\n",
    "* Develop a Predictive Model: Employ machine learning techniques to build a model capable of predicting sepsis based on patient data.\n",
    "* Develop FastAPI for deployment of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "`Null Hypothesis (H0)`:\n",
    "\n",
    "There is no association between Age and the likelihood of developing Sepsis.\n",
    "\n",
    "\n",
    "`Alternative Hypothesis (H1)`:\n",
    "\n",
    "There is a significant association between Age and the likelihood of developing Sepsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand our data needs for this project, we have to load and critically examine features and other properties of the data.\n",
    "\n",
    "We therefore load the Python libraries that are necessary for this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Paitients_Files_Train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\sepsisClassification_arr\\Sepsis-Classification\\SepsisClassification.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/sepsisClassification_arr/Sepsis-Classification/SepsisClassification.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load data and inspect the first five rows.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/sepsisClassification_arr/Sepsis-Classification/SepsisClassification.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../data/Paitients_Files_Train.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/sepsisClassification_arr/Sepsis-Classification/SepsisClassification.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Paitients_Files_Train.csv'"
     ]
    }
   ],
   "source": [
    "# Load data and inspect the first five rows.\n",
    "train = pd.read_csv(\"../data/Paitients_Files_Train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After critical inspection of the dataset, we researched about the variables and other general information. We therefore came out with the following:\n",
    "\n",
    "`PRG` (Plasma Glucose): High plasma glucose levels may be associated with conditions like diabetes, and such conditions could potentially contribute to an increased risk of sepsis..\n",
    "\n",
    "`PL` (Glucose): Elevated glucose levels could be indicative of metabolic dysfunction, which may be associated with an increased risk of infection and sepsis.\n",
    "\n",
    "`PR` (Blood Pressure): Diastolic blood pressure is a crucial cardiovascular indicator. Abnormalities in blood pressure may signal systemic issues, including potential infection.\n",
    "\n",
    "`SK` (Skin Thickness): Triceps skinfold thickness could be related to the patient's overall nutritional status and body composition. Malnutrition may affect the immune system and increase susceptibility to infections.\n",
    "\n",
    "`TS` (Insulin): Abnormal insulin levels may be associated with underlying metabolic conditions, which could impact the body's ability to respond to infections.\n",
    "\n",
    "`M11` (BMI): Body Mass Index is a measure of body fat and may indicate whether a patient is underweight, normal weight, overweight, or obese. BMI is linked to overall health, and extremes in either direction may affect the immune system.\n",
    "\n",
    "`BD2` (Diabetes Pedigree Function): This function provides a measure of the genetic influence of diabetes. Genetic factors can contribute to overall health and may influence the risk of developing conditions, including sepsis.\n",
    "\n",
    "`Age`: Age is a critical factor, as the risk of sepsis tends to increase with age. Older individuals may have weakened immune systems or pre-existing health conditions that make them more susceptible to infections.\n",
    "\n",
    "`Insurance`: While not a direct health indicator, insurance status may indirectly reflect the patient's access to healthcare. <br>Timely access to medical care can impact the management of infections and reduce the risk of sepsis.\n",
    "\n",
    "These features collectively provide a diverse set of information about the patient's health, lifestyle, and potential risk factors.<br>\n",
    " Machine learning models, such as logistic regression or decision trees, can analyze these features to identify patterns associated with the likelihood of sepsis. <br>The goal is to train a model that can generalize from the known cases in the dataset to predict sepsis accurately in new, unseen cases based on their feature values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "new_column_names = {\n",
    "    'PRG': 'Plasma Glucose',\n",
    "    'PL': 'Elevated Glucose',\n",
    "    'PR': 'Diastolic Blood Pressure',\n",
    "    'SK': 'Triceps Skinfold Thickness',\n",
    "    'TS': 'Insulin Levels',\n",
    "    'M11': 'Body Mass Index (BMI)',\n",
    "    'BD2': 'Diabetes Pedigree Function',\n",
    "    'Age': 'Age',\n",
    "    'Insurance': 'Insurance',\n",
    "    'Sepssis': 'Sepsis'\n",
    "}\n",
    "\n",
    "train = train.rename(columns=new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Non-nulls and data type of each feature and memory used.\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a statistical summary for data.\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique values and their counts for each feature.\n",
    "\n",
    "for col in train.columns:\n",
    "    print(f'\\n{col}------->{train[col].value_counts()}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for number of duplicates\n",
    "\n",
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Questions\n",
    "\n",
    "* How does the distribution of sepsis cases differ between patients with insurance and those without insurance?\n",
    "\n",
    "* Is there an observable trend in sepsis risk based on the levels of insulin (TS) and the associated pedigree function (BD2) in the dataset?\n",
    "\n",
    "* Is there any correlation between age and the likelihood of developing sepsis?\n",
    "\n",
    "* Does age contribute significantly to the influence of other factors on sepsis development?\n",
    "\n",
    "* Is there a correlation between patients' BMI and the outcome of sepsis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_univariate_analysis(df, cols_to_plot):\n",
    "    # Create subplots based on the number of columns to be plotted\n",
    "    fig, axes = plt.subplots(nrows=len(cols_to_plot), figsize=(12, 6 * len(cols_to_plot)))\n",
    "\n",
    "    # Loop through each column for univariate analysis\n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        # Select the current subplot\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Plot histogram with KDE (Kernel Density Estimate)\n",
    "        sns.histplot(data=df, x=col, kde=True, ax=ax, fill=True)\n",
    "        \n",
    "        # Set x-axis and y-axis labels\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title(f'Univariate Analysis of {col}')\n",
    "\n",
    "        # Calculate and display mean, skewness, and kurtosis\n",
    "        mean_val = df[col].mean()\n",
    "        skewness_val = df[col].skew()\n",
    "        kurtosis_val = df[col].kurtosis()\n",
    "\n",
    "        ax.text(0.65, 0.9, f'Mean: {mean_val:.2f}', transform=ax.transAxes)\n",
    "        ax.text(0.65, 0.8, f'Skewness: {skewness_val:.2f}', transform=ax.transAxes)\n",
    "        ax.text(0.65, 0.7, f'Kurtosis: {kurtosis_val:.2f}', transform=ax.transAxes)\n",
    "\n",
    "        # Draw a vertical dashed line at the mean\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', label='Mean')\n",
    "\n",
    "        # Identify potential outliers\n",
    "        outliers = df[(df[col] > mean_val + 3 * df[col].std()) | (df[col] < mean_val - 3 * df[col].std())]\n",
    "        \n",
    "        # Plot potential outliers in red\n",
    "        ax.plot(outliers[col], [0] * len(outliers), 'ro', label='Potential Outliers')\n",
    "\n",
    "        # Display legend\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout for better visualization\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "plot_univariate_analysis(train, ['Plasma Glucose', 'Elevated Glucose', 'Diastolic Blood Pressure', 'Triceps Skinfold Thickness', 'Insulin Levels', 'Body Mass Index (BMI)', 'Diabetes Pedigree Function', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the distribution of the target variable and the Insurance column\n",
    "def plot_distribution(data, column, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.histplot(data[column])\n",
    "\n",
    "    for rect in plt.gca().patches:\n",
    "        height = rect.get_height()\n",
    "        plt.gca().annotate(f'{height:.0f}', \n",
    "                           xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                           xytext=(0, 3),  # 3 points vertical offset\n",
    "                           textcoords=\"offset points\",\n",
    "                           ha='center')\n",
    "\n",
    "    plt.title(f'Distribution of {title}')\n",
    "    plt.xlabel(title)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of Sepsis and Insurance columns by invoking the function plot_distribution()\n",
    "plot_distribution(train, 'Sepsis', 'Sepsis')\n",
    "plot_distribution(train, 'Insurance', 'Insurance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering the analytical questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  ### How does the distribution of sepsis cases differ between patients with insurance and those without insurance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "ax =sns.countplot(x='Insurance', hue='Sepsis', data=train, palette='Set2')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Insurance')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.title('Distribution of Sepsis Cases by Insurance Status')\n",
    "plt.legend(title='Sepssis', loc='upper left')\n",
    "\n",
    "# Adding labels on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sepsis Patients with No Insurance:`<br>\n",
    "According to the information, there are 57 sepsis patients with no insurance.\n",
    "\n",
    "\n",
    "`Negative Sepsis Cases for No Insurance:`<br>\n",
    "The visualization shows a bar corresponding to the 'Negative' category for patients with no insurance. According to the information, there are 131 patients in this category.\n",
    "\n",
    "\n",
    "`Positive Sepsis Cases for No Insurance:`<br>\n",
    "The 'Positive' category for sepsis patients with no insurance is not explicitly mentioned in the provided information, but it can be inferred that the remaining patients in the 'No Insurance' category (57) must be 'Positive.'\n",
    "\n",
    "\n",
    "`Positive Sepsis Cases for Insurance:`<br>\n",
    "The information indicates that there are 151 sepsis patients with insurance and positive sepsis cases.\n",
    "\n",
    "\n",
    "`Negative Sepsis Cases for Insurance:`<br>\n",
    "The information mentions 260 patients with insurance and negative sepsis cases.\n",
    "\n",
    "\n",
    "Based on this interpretation, the visualization allows for a quick comparison of the distribution of sepsis cases among patients with and without insurance. The heights of the bars represent the counts of patients in each category. The legend provides clarity on the color-coding, distinguishing between 'Negative' and 'Positive' sepsis outcomes.\n",
    "\n",
    "It's evident from the visualization that the 'Negative' cases are more prevalent than 'Positive' cases in both insurance categories. This information is valuable for understanding the distribution of sepsis cases and can potentially inform further analyses or interventions related to sepsis management and prevention, especially in the context of insurance coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ##  Is there an observable trend in sepsis risk based on the levels of insulin (TS) and the associated pedigree function (BD2) in the dataset?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Is there a correlation between patients' BMI and the outcome of sepsis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(x='Insulin Levels', y='Diabetes Pedigree Function', hue='Sepsis', data=train, palette='Set1', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Insulin Levels')\n",
    "plt.ylabel('Diabetes Pedigree Function (BD2)')\n",
    "plt.title('Scatter Plot of Sepsis Risk Based on Levels of Insulin and Pedigree Function')\n",
    "\n",
    "plt.legend(title='Sepsis', loc='upper right')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ## Is there any correlation between age and the likelihood of developing sepsis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Sepsis', y='Age', data=train, palette='Set1')\n",
    "plt.xlabel('Sepsis')\n",
    "plt.ylabel('Age')\n",
    "plt.title('Box Plot of Age vs. Sepsis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a contingency table\n",
    "contingency_table = pd.crosstab(train['Age'], train['Sepsis'])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(f'Chi-square statistic: {chi2}')\n",
    "print(f'p-value: {p}')\n",
    "\n",
    "# Check if the correlation is statistically significant\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print('The correlation between Age and Sepsis is statistically significant.')\n",
    "else:\n",
    "    print('There is no significant correlation between Age and Sepsis.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ##  Does age contribute significantly to the influence of other factors on sepsis development?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = train[['Age', 'Plasma Glucose', 'Elevated Glucose', 'Diastolic Blood Pressure', 'Triceps Skinfold Thickness', 'Insulin Levels', 'Body Mass Index (BMI)', 'Diabetes Pedigree Function', 'Insurance']].corr()\n",
    "print(correlation_matrix['Age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficients between 'Age' and the other factors are as follows:\n",
    "\n",
    "`Plasma Glucose (0.53)`: A moderately positive correlation suggests that as 'Plasma Glucose' levels increase, 'Age' tends to increase as well. This could indicate a potential association between higher glucose levels and older age.\n",
    "\n",
    "`Elevated Glucose (0.27)`: A positive correlation, though weaker than 'Plasma Glucose', implies that as 'Elevated Glucose' levels increase, 'Age' tends to increase. This correlation is weaker compared to 'Plasma Glucose'.\n",
    "\n",
    "`Diastolic Blood Pressure (0.23)`: A positive correlation indicates that higher 'Diastolic Blood Pressure' is associated with older age. The strength of the correlation is moderate.\n",
    "\n",
    "`Triceps Skinfold Thickness (-0.12)`: A weak negative correlation suggests that as 'Triceps Skinfold Thickness' increases, 'Age' tends to be lower. The negative sign indicates an inverse relationship, but the correlation is weak.\n",
    "\n",
    "`Insulin Levels (-0.01)`: A very weak negative correlation suggests a negligible relationship between 'Insulin Levels' and 'Age'.\n",
    "\n",
    "`Body Mass Index (BMI) (0.05)`: A weak positive correlation implies that as 'BMI' increases, 'Age' tends to be higher.\n",
    "\n",
    "`Diabetes Pedigree Function (0.03)`: A very weak positive correlation suggests a negligible relationship between 'Diabetes Pedigree Function' and 'Age'.\n",
    "\n",
    "`Insurance (0.05)`: A weak positive correlation indicates a slight tendency for individuals with insurance to be older.\n",
    "\n",
    "Overall, the correlation analysis provides insights into the direction and strength of the relationships between 'Age' and other factors. Knowing that correlation does not imply causation, further analysis such as regression models, would be needed to understand the combined influence of these factors on the likelihood of sepsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ## Giv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('ID', axis=1)\n",
    "\n",
    "# Split the data into features (X) and the target variable (y)\n",
    "X_train = train.drop('Sepsis', axis=1)\n",
    "y_train = train['Sepsis']\n",
    "\n",
    "# Exclude non-numeric columns before scaling\n",
    "numeric_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "X_train_numeric = X_train[numeric_columns]\n",
    "\n",
    "# Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
    "\n",
    "# Fit a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature coefficients\n",
    "coefficients = model.coef_[0]\n",
    "feature_names = X_train_numeric.columns\n",
    "\n",
    "# Create a DataFrame to display coefficients\n",
    "coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "# Sort the DataFrame by absolute coefficient values to identify the most important features\n",
    "coefficients_df['Absolute_Coefficient'] = abs(coefficients_df['Coefficient'])\n",
    "coefficients_df = coefficients_df.sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(coefficients_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elevated Glucose (1.036):\n",
    "\n",
    "Elevated Glucose has the highest positive coefficient, suggesting it is the most influential feature in predicting sepsis. An increase in Elevated Glucose is associated with a substantial increase in the log-odds of sepsis.\n",
    "Body Mass Index (BMI) (0.794):\n",
    "\n",
    "BMI has the second-highest positive coefficient, indicating that higher BMI contributes significantly to the likelihood of sepsis.\n",
    "Plasma Glucose (0.387):\n",
    "\n",
    "Plasma Glucose also has a positive coefficient, contributing to the prediction of sepsis, but with a smaller magnitude compared to Elevated Glucose and BMI.\n",
    "Diabetes Pedigree Function (0.342):\n",
    "\n",
    "The Diabetes Pedigree Function has a positive coefficient, suggesting a moderate influence on sepsis risk.\n",
    "Diastolic Blood Pressure (-0.182):\n",
    "\n",
    "Diastolic Blood Pressure has a negative coefficient, indicating that higher diastolic blood pressure is associated with a decrease in the likelihood of sepsis. This is a notable finding and may warrant further investigation.\n",
    "Age (0.102):\n",
    "\n",
    "Age has a positive coefficient, indicating that as age increases, the likelihood of sepsis also increases. However, its impact is smaller compared to other features.\n",
    "Insulin Levels (-0.100):\n",
    "\n",
    "Insulin Levels have a negative coefficient, suggesting that higher insulin levels are associated with a decrease in the likelihood of sepsis.\n",
    "Insurance (0.076):\n",
    "\n",
    "Insurance has a positive coefficient, indicating a relatively smaller impact on the likelihood of sepsis.\n",
    "Triceps Skinfold Thickness (-0.033):\n",
    "\n",
    "Triceps Skinfold Thickness has a negative coefficient, suggesting that higher thickness is associated with a decrease in the likelihood of sepsis.\n",
    "Interpretation:\n",
    "\n",
    "Features with higher absolute coefficients (Elevated Glucose, BMI) have a more substantial impact on the model's predictions.\n",
    "\n",
    "Negative coefficients for Diastolic Blood Pressure, Insulin Levels, and Triceps Skinfold Thickness suggest that higher values of these features are associated with a lower likelihood of sepsis.\n",
    "\n",
    "Consider the clinical context and domain knowledge to interpret these results effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Sepsis'\n",
    "\n",
    "# Define numerical features\n",
    "features = train.select_dtypes(include=['float64', 'int64']).columns.difference(['Insurance'])\n",
    "\n",
    "# Remove outliers\n",
    "Q1 = train[features].apply(pd.to_numeric, errors='coerce').quantile(0.25)\n",
    "Q3 = train[features].apply(pd.to_numeric, errors='coerce').quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_mask = ((train[features].apply(pd.to_numeric, errors='coerce') < (Q1 - 1.5 * IQR)) | (train[features].apply(pd.to_numeric, errors='coerce') > (Q3 + 1.5 * IQR)))\n",
    "train_cleaned = train[~outlier_mask.any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into features (X) and the target variable (y)\n",
    "X = train_cleaned.drop(target_column, axis=1)\n",
    "y = train_cleaned[target_column]\n",
    "\n",
    "# Preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), X.columns),\n",
    "        ('log_transformation', FunctionTransformer(np.log1p), X.columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Applying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and evaluation sets\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Label encoding\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_eval_encoded = encoder.transform(y_eval)\n",
    "\n",
    "# List of models\n",
    "models = [SVC(), GaussianNB(), DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "          XGBClassifier(), GradientBoostingClassifier(), AdaBoostClassifier(), LogisticRegression()]\n",
    "\n",
    "# Results DataFrame\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# Iterating over models\n",
    "for model in models:\n",
    "    # Create a pipeline with the preprocessor and the model\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Predict using the evaluation set\n",
    "    y_pred = pipeline.predict(X_eval)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    acc = accuracy_score(y_eval_encoded, y_pred)\n",
    "    f1 = f1_score(y_eval_encoded, y_pred)\n",
    "    roc = roc_auc_score(y_eval_encoded, y_pred)\n",
    "    pr = precision_score(y_eval_encoded, y_pred)\n",
    "    rc = recall_score(y_eval_encoded, y_pred)\n",
    "\n",
    "    # Append the results\n",
    "    result = pd.DataFrame({\n",
    "        \"Model\": [model.__class__.__name__],\n",
    "        \"Accuracy\": [acc],\n",
    "        \"F1 Score\": [f1],\n",
    "        \"ROC AUC\": [roc],\n",
    "        \"Precision\": [pr],\n",
    "        \"Recall\": [rc]\n",
    "    })\n",
    "    results = pd.concat([results, result])\n",
    "\n",
    "# Display the overall performance\n",
    "results = results.sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could there be overfitting?\n",
    "\n",
    "Let's check by comparing the performance of our models on the training set and the evaluation set. If a model performs significantly better on the training set compared to the evaluation set, it might be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results DataFrame\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# Iterating over models\n",
    "for model in models:\n",
    "    # Create a pipeline with the preprocessor and the model\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Predict using the training set\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train_encoded, y_train_pred)\n",
    "\n",
    "    # Predict using the evaluation set\n",
    "    y_eval_pred = pipeline.predict(X_eval)\n",
    "    eval_acc = accuracy_score(y_eval_encoded, y_eval_pred)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(y_eval_encoded, y_eval_pred)\n",
    "    roc = roc_auc_score(y_eval_encoded, y_eval_pred)\n",
    "    pr = precision_score(y_eval_encoded, y_eval_pred)\n",
    "    rc = recall_score(y_eval_encoded, y_eval_pred)\n",
    "\n",
    "    # Append the results\n",
    "    result = pd.DataFrame({\n",
    "        \"Model\": [model.__class__.__name__],\n",
    "        \"Train Accuracy\": [train_acc],\n",
    "        \"Eval Accuracy\": [eval_acc],\n",
    "        \"F1 Score\": [f1],\n",
    "        \"ROC AUC\": [roc],\n",
    "        \"Precision\": [pr],\n",
    "        \"Recall\": [rc]\n",
    "    })\n",
    "    results = pd.concat([results, result])\n",
    "\n",
    "# Display the overall performance\n",
    "results = results.sort_values(by=\"Eval Accuracy\", ascending=False).reset_index(drop=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier and XGBClassifier:\n",
    "\n",
    "Train Accuracy: 100%: These models seem to have memorized the training data, achieving perfect accuracy. This might be a sign of overfitting.\n",
    "Eval Accuracy: 85.93%: Both models perform well on the evaluation set, and their accuracies are similar, indicating good generalization.\n",
    "F1 Score: High F1 scores suggest a good balance between precision and recall.\n",
    "ROC AUC: Represents the area under the receiver operating characteristic curve. High ROC AUC values indicate good model performance.\n",
    "Precision and Recall: Balanced values for precision and recall suggest a good trade-off between false positives and false negatives.\n",
    "\n",
    "\n",
    "GradientBoostingClassifier:\n",
    "\n",
    "Train Accuracy: 95.55%: A high but not perfect accuracy on the training set.\n",
    "Eval Accuracy: 82.22%: A good accuracy on the evaluation set, but slightly lower than RandomForest and XGBClassifier.\n",
    "F1 Score: Represents a good balance between precision and recall.\n",
    "ROC AUC: Good performance but slightly lower than RandomForest and XGBClassifier.\n",
    "\n",
    "\n",
    "DecisionTreeClassifier and AdaBoostClassifier:\n",
    "\n",
    "Train Accuracy: 100% for DecisionTreeClassifier, 84.97% for AdaBoostClassifier.\n",
    "Eval Accuracy: DecisionTreeClassifier - 79.26%, AdaBoostClassifier - 79.26%: Both models have good accuracies but might be overfitting.\n",
    "F1 Score: Indicates a good balance between precision and recall.\n",
    "ROC AUC: Good performance but slightly lower than RandomForest and XGBClassifier.\n",
    "\n",
    "\n",
    "GaussianNB:\n",
    "\n",
    "Train Accuracy: 74.77%: A moderate accuracy on the training set.\n",
    "Eval Accuracy: 77.04%: A decent accuracy on the evaluation set.\n",
    "F1 Score: Represents a good balance between precision and recall.\n",
    "ROC AUC: Decent performance.\n",
    "\n",
    "\n",
    "SVC and LogisticRegression:\n",
    "\n",
    "Train Accuracy: 75.14% for SVC, 75.70% for LogisticRegression: Moderate accuracies on the training set.\n",
    "Eval Accuracy: 76.30% for SVC, 74.81% for LogisticRegression: Decent accuracies on the evaluation set.\n",
    "F1 Score: Represents a good balance between precision and recall.\n",
    "ROC AUC: Decent performance.\n",
    "In summary, RandomForestClassifier and XGBClassifier achieved the highest evaluation accuracy, but potential overfitting is suggested by their perfect training accuracy. GradientBoostingClassifier also performed well. DecisionTreeClassifier and AdaBoostClassifier showed good accuracy but might be overfitting. GaussianNB, SVC, and LogisticRegression had moderate accuracies but performed decently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features\n",
    "features = train.select_dtypes(include=['float64', 'int64']).columns.difference(['Insurance'])\n",
    "\n",
    "# Creating a copy of the DataFrame to preserve the original data\n",
    "df_trim = train.copy()\n",
    "\n",
    "# Calculating the IQR\n",
    "Q1 = train[features].quantile(0.25)\n",
    "Q3 = train[features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Creating a mask to identify outliers\n",
    "outlier_mask = ((train[features] < (Q1 - 1.5 * IQR)) | (train[features] > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "# Removing outliers\n",
    "df_trim = df_trim[~outlier_mask.any(axis=1)]\n",
    "\n",
    "\n",
    "# Split the data into features (X) and the target variable (y)\n",
    "X = df_trim.drop('Sepsis', axis=1)\n",
    "y = df_trim['Sepsis']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define input features excluding 'Insurance'\n",
    "input_features = X.columns.difference(['Insurance'])\n",
    "\n",
    "# Preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), input_features),\n",
    "        ('log_transformation', FunctionTransformer(np.log1p), input_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Applying SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X[input_features], y_encoded)\n",
    "\n",
    "# Split the data into training and evaluation sets\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# List of models\n",
    "models = [\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    SVC(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "cv_results = []\n",
    "for model in models:\n",
    "    # Create a pipeline with the preprocessor and the model\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    scores = cross_val_score(pipeline, X, y_encoded, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Append the results to the list\n",
    "    cv_results.append({\n",
    "        \"Model\": model.__class__.__name__,\n",
    "        \"Cross-Validation Mean Accuracy\": np.mean(scores),\n",
    "        \"Cross-Validation Standard Deviation\": np.std(scores)\n",
    "    })\n",
    "\n",
    "# Display the cross-validation results\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "cv_results_df = cv_results_df.sort_values(by=\"Cross-Validation Mean Accuracy\", ascending=False)\n",
    "cv_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: The name of the machine learning model.\n",
    "Cross-Validation Mean Accuracy: The average accuracy of the model across the five folds of cross-validation. This metric gives an indication of how well the model generalizes to new, unseen data.\n",
    "Cross-Validation Standard Deviation: The standard deviation of the accuracy scores across the five folds. It measures the variability or consistency of the model's performance during cross-validation.\n",
    "\n",
    "\n",
    "Interpretation of the results:\n",
    "\n",
    "SVC (Support Vector Classifier): Achieves the highest mean accuracy of approximately 78.30% with a relatively low standard deviation of 0.78%. This suggests that SVC provides a consistent and accurate performance across different folds.\n",
    "\n",
    "RandomForestClassifier: Shows the second-highest mean accuracy of around 77.28%, with a standard deviation of 2.10%. It provides a good balance between accuracy and consistency.\n",
    "\n",
    "LogisticRegression: Performs well with a mean accuracy of about 77.09%, and it has a standard deviation of 2.96%. It's consistent and accurate.\n",
    "\n",
    "GradientBoostingClassifier: Achieves a mean accuracy of approximately 75.27% with a slightly higher standard deviation of 4.22%. While it provides good accuracy, there is a bit more variability in its performance.\n",
    "\n",
    "XGBClassifier: Has a mean accuracy of around 74.66% and a standard deviation of 3.83%. Similar to Gradient Boosting, it offers good accuracy but with a bit more variability.\n",
    "\n",
    "GaussianNB (Gaussian Naive Bayes): Shows a mean accuracy of about 73.85% and a standard deviation of 3.14%. It provides reasonable accuracy but with more variability compared to some other models.\n",
    "\n",
    "AdaBoostClassifier: Achieves a mean accuracy of approximately 72.62% with a standard deviation of 2.35%. It offers decent accuracy but with less consistency compared to some other models.\n",
    "\n",
    "DecisionTreeClassifier: Performs with a mean accuracy of around 70.59% and a standard deviation of 4.24%. It provides a lower mean accuracy and higher variability compared to other models.\n",
    "\n",
    "In summary, SVC, RandomForestClassifier, and LogisticRegression appear to be the top-performing models in terms of both accuracy and consistency based on cross-validation results.\n",
    "\n",
    "We therefore persist the RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline with preprocessor and RandomForestClassifier\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the final pipeline on the entire dataset\n",
    "final_pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Save the pipeline to a file\n",
    "joblib.dump(final_pipeline, 'sepsis_classification_pipeline.joblib')\n",
    "\n",
    "# Save the RandomForestClassifier model separately\n",
    "rf_model = final_pipeline.named_steps['model']\n",
    "joblib.dump(rf_model, 'random_forest_model.joblib')\n",
    "\n",
    "print(\"Pipeline and model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LabelEncoder\n",
    "joblib.dump(encoder, 'label_encoder.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
